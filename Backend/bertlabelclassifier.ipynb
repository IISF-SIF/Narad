{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7428570,"sourceType":"datasetVersion","datasetId":4322772},{"sourceId":7428604,"sourceType":"datasetVersion","datasetId":4322797},{"sourceId":7428640,"sourceType":"datasetVersion","datasetId":4322823},{"sourceId":7428839,"sourceType":"datasetVersion","datasetId":4322955}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tqdm transformers torch","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:54:05.307831Z","iopub.execute_input":"2024-01-18T14:54:05.308196Z","iopub.status.idle":"2024-01-18T14:54:15.422187Z","shell.execute_reply.started":"2024-01-18T14:54:05.308169Z","shell.execute_reply":"2024-01-18T14:54:15.420598Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:55:15.984175Z","iopub.execute_input":"2024-01-18T14:55:15.984797Z","iopub.status.idle":"2024-01-18T14:55:16.423229Z","shell.execute_reply.started":"2024-01-18T14:55:15.984763Z","shell.execute_reply":"2024-01-18T14:55:16.422428Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom tqdm.notebook import tqdm\n\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\n\nfrom transformers import BertForSequenceClassification\n\ndf = pd.read_csv('/kaggle/input/classifierbert/classifier.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:57:29.669168Z","iopub.execute_input":"2024-01-18T14:57:29.669547Z","iopub.status.idle":"2024-01-18T14:57:29.689143Z","shell.execute_reply.started":"2024-01-18T14:57:29.669517Z","shell.execute_reply":"2024-01-18T14:57:29.688272Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               Input   Query\n0  What is the meaning of \"Bhuvan\" in Sanskrit, a...  Bhuvan\n1  How can the public access Bhuvan, and what typ...  Bhuvan\n2  What role does the National Remote Sensing Cen...  Bhuvan\n3  Could you provide examples of the practical ap...  Bhuvan\n4  How does Bhuvan contribute to ISRO's Earth Obs...  Bhuvan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Input</th>\n      <th>Query</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the meaning of \"Bhuvan\" in Sanskrit, a...</td>\n      <td>Bhuvan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How can the public access Bhuvan, and what typ...</td>\n      <td>Bhuvan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What role does the National Remote Sensing Cen...</td>\n      <td>Bhuvan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Could you provide examples of the practical ap...</td>\n      <td>Bhuvan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How does Bhuvan contribute to ISRO's Earth Obs...</td>\n      <td>Bhuvan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Query'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:57:32.975760Z","iopub.execute_input":"2024-01-18T14:57:32.976689Z","iopub.status.idle":"2024-01-18T14:57:32.986116Z","shell.execute_reply.started":"2024-01-18T14:57:32.976649Z","shell.execute_reply":"2024-01-18T14:57:32.985114Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Query\nBhuvan        10\nAadhaar       10\nAddPoint      10\nDrawing       10\nNavMap        10\n              ..\nHarState      10\nNARL          10\nGanga         10\nHeatwave      10\nNOEDAWater    10\nName: count, Length: 88, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"possible_labels = df.Query.unique()\n\nlabel_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:57:48.737141Z","iopub.execute_input":"2024-01-18T14:57:48.737503Z","iopub.status.idle":"2024-01-18T14:57:48.750413Z","shell.execute_reply.started":"2024-01-18T14:57:48.737476Z","shell.execute_reply":"2024-01-18T14:57:48.749437Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'Bhuvan': 0,\n 'Aadhaar': 1,\n 'MGNREGA': 2,\n 'NRSC': 3,\n 'Bhuvan2D': 4,\n 'Geospatial': 5,\n 'Yuktdhara': 6,\n 'Bhuvan3D': 7,\n 'WBIS': 8,\n 'RUSA': 9,\n 'GI': 10,\n 'Flycatch': 11,\n 'NCERT': 12,\n 'GIS': 13,\n 'Tourism': 14,\n 'Hpfor': 15,\n 'TelFor': 16,\n 'PunFor': 17,\n 'UkFor': 18,\n 'KarFor': 19,\n 'NDEM': 20,\n 'Thematic': 21,\n 'Agro': 22,\n 'PMKSY': 23,\n 'Heatwave': 24,\n 'Ganga': 25,\n 'NARL': 26,\n 'HarState': 27,\n 'Saras': 28,\n 'Satell': 29,\n 'PMJVK': 30,\n 'Anganwadi': 31,\n 'Covid': 32,\n 'Organiz': 33,\n 'NOEDA': 34,\n 'RBI': 35,\n 'Geoportal': 36,\n 'AmTourism': 37,\n 'LudMun': 38,\n 'Toll': 39,\n 'KALAMTARI': 40,\n 'Geomorph': 41,\n 'AgroPortal': 42,\n 'DeltaPortal': 43,\n 'CDMAPortal': 44,\n 'AndhraSat': 45,\n 'Multilingual': 46,\n 'GeoTaggingLight': 47,\n 'GeoTaggingAgri': 48,\n 'AIBP': 49,\n 'MahaWater': 50,\n 'PMGSY': 51,\n 'Collab': 52,\n 'PunHer': 53,\n 'PunGIS': 54,\n 'LudMunCollab': 55,\n 'AIBPCollab': 56,\n 'IMD': 57,\n 'Register': 58,\n '2DHelp': 59,\n 'BhuvanFind': 60,\n 'Admin': 61,\n 'NavMap': 62,\n 'Drawing': 63,\n 'AddPoint': 64,\n 'AddLine': 65,\n 'AddPolygon': 66,\n 'Area': 67,\n 'Distance': 68,\n 'Pan': 69,\n 'Land': 70,\n 'Weather2D': 71,\n 'Ocean2D': 72,\n 'Disaster2D': 73,\n '3Don2D': 74,\n 'Dissemination': 75,\n 'Visualization': 76,\n 'Statistics': 77,\n 'Analysis': 78,\n 'Metadata': 79,\n 'WebService': 80,\n 'Layers': 81,\n 'Information': 82,\n 'Tools': 83,\n 'NOEDASatellite': 84,\n 'NOEDACrop': 85,\n 'NOEDAAWiFS': 86,\n 'NOEDAWater': 87}"},"metadata":{}}]},{"cell_type":"code","source":"df['label'] = df.Query.replace(label_dict)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:58:02.563458Z","iopub.execute_input":"2024-01-18T14:58:02.564324Z","iopub.status.idle":"2024-01-18T14:58:02.600045Z","shell.execute_reply.started":"2024-01-18T14:58:02.564292Z","shell.execute_reply":"2024-01-18T14:58:02.599067Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(df.index.values, \n                                                  df.label.values, \n                                                  test_size=0.15, \n                                                  random_state=42, \n                                                  stratify=df.label.values)\n\ndf['data_type'] = ['not_set']*df.shape[0]\n\ndf.loc[X_train, 'data_type'] = 'train'\ndf.loc[X_val, 'data_type'] = 'val'\n\ndf.groupby(['Query', 'label', 'data_type']).count()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:58:45.371133Z","iopub.execute_input":"2024-01-18T14:58:45.371738Z","iopub.status.idle":"2024-01-18T14:58:45.871968Z","shell.execute_reply.started":"2024-01-18T14:58:45.371680Z","shell.execute_reply":"2024-01-18T14:58:45.871097Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                            Input\nQuery      label data_type       \n2DHelp     59    train          8\n                 val            2\n3Don2D     74    train          8\n                 val            2\nAIBP       49    train          9\n...                           ...\nWeather2D  71    val            2\nWebService 80    train          9\n                 val            1\nYuktdhara  6     train          8\n                 val            2\n\n[176 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Input</th>\n    </tr>\n    <tr>\n      <th>Query</th>\n      <th>label</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">2DHelp</th>\n      <th rowspan=\"2\" valign=\"top\">59</th>\n      <th>train</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">3Don2D</th>\n      <th rowspan=\"2\" valign=\"top\">74</th>\n      <th>train</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>AIBP</th>\n      <th>49</th>\n      <th>train</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Weather2D</th>\n      <th>71</th>\n      <th>val</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">WebService</th>\n      <th rowspan=\"2\" valign=\"top\">80</th>\n      <th>train</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Yuktdhara</th>\n      <th rowspan=\"2\" valign=\"top\">6</th>\n      <th>train</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>176 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True)\n                                          \nencoded_data_train = tokenizer.batch_encode_plus(\n    df[df.data_type=='train'].Input.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\nencoded_data_val = tokenizer.batch_encode_plus(\n    df[df.data_type=='val'].Input.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(df[df.data_type=='train'].label.values)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(df[df.data_type=='val'].label.values)\n\ndataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:59:41.917856Z","iopub.execute_input":"2024-01-18T14:59:41.918583Z","iopub.status.idle":"2024-01-18T14:59:43.033860Z","shell.execute_reply.started":"2024-01-18T14:59:41.918551Z","shell.execute_reply":"2024-01-18T14:59:43.033005Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:59:54.308570Z","iopub.execute_input":"2024-01-18T14:59:54.309395Z","iopub.status.idle":"2024-01-18T14:59:56.810241Z","shell.execute_reply.started":"2024-01-18T14:59:54.309362Z","shell.execute_reply":"2024-01-18T14:59:56.809477Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7060aac6fd124d07b82b52369da6e4c6"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\nbatch_size = 3\n\ndataloader_train = DataLoader(dataset_train, \n                              sampler=RandomSampler(dataset_train), \n                              batch_size=batch_size)\n\ndataloader_validation = DataLoader(dataset_val, \n                                   sampler=SequentialSampler(dataset_val), \n                                   batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:00:06.100128Z","iopub.execute_input":"2024-01-18T15:00:06.100940Z","iopub.status.idle":"2024-01-18T15:00:06.106197Z","shell.execute_reply.started":"2024-01-18T15:00:06.100910Z","shell.execute_reply":"2024-01-18T15:00:06.105152Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\noptimizer = AdamW(model.parameters(),\n                  lr=1e-5, \n                  eps=1e-8)\n                  \nepochs = 5\n\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0,\n                                            num_training_steps=len(dataloader_train)*epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:00:28.842334Z","iopub.execute_input":"2024-01-18T15:00:28.842679Z","iopub.status.idle":"2024-01-18T15:00:28.853615Z","shell.execute_reply.started":"2024-01-18T15:00:28.842652Z","shell.execute_reply":"2024-01-18T15:00:28.852716Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef accuracy_per_class(preds, labels):\n    label_dict_inverse = {v: k for k, v in label_dict.items()}\n    \n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n\n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat==label]\n        y_true = labels_flat[labels_flat==label]\n        print(f'Class: {label_dict_inverse[label]}')\n        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:00:52.152500Z","iopub.execute_input":"2024-01-18T15:00:52.152860Z","iopub.status.idle":"2024-01-18T15:00:52.160313Z","shell.execute_reply.started":"2024-01-18T15:00:52.152831Z","shell.execute_reply":"2024-01-18T15:00:52.159314Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:01:56.493769Z","iopub.execute_input":"2024-01-18T15:01:56.494396Z","iopub.status.idle":"2024-01-18T15:01:56.498620Z","shell.execute_reply.started":"2024-01-18T15:01:56.494365Z","shell.execute_reply":"2024-01-18T15:01:56.497590Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:04:23.219454Z","iopub.execute_input":"2024-01-18T15:04:23.220437Z","iopub.status.idle":"2024-01-18T15:04:23.494044Z","shell.execute_reply.started":"2024-01-18T15:04:23.220390Z","shell.execute_reply":"2024-01-18T15:04:23.493128Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:04:51.256412Z","iopub.execute_input":"2024-01-18T15:04:51.257396Z","iopub.status.idle":"2024-01-18T15:05:18.381117Z","shell.execute_reply.started":"2024-01-18T15:04:51.257364Z","shell.execute_reply":"2024-01-18T15:05:18.379826Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2345994ed48432fbe6c2149bf1d1607"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 79\u001b[0m\n\u001b[1;32m     74\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     76\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch))})\n\u001b[0;32m---> 79\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_volume/finetuned_BERT_epoch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m loss_train_avg \u001b[38;5;241m=\u001b[39m loss_train_total\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader_train)            \n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mRuntimeError\u001b[0m: Parent directory data_volume does not exist."],"ename":"RuntimeError","evalue":"Parent directory data_volume does not exist.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:07:23.305163Z","iopub.execute_input":"2024-01-18T15:07:23.306008Z","iopub.status.idle":"2024-01-18T15:07:23.310976Z","shell.execute_reply.started":"2024-01-18T15:07:23.305974Z","shell.execute_reply":"2024-01-18T15:07:23.309946Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:07:36.912622Z","iopub.execute_input":"2024-01-18T15:07:36.913010Z","iopub.status.idle":"2024-01-18T15:07:36.924564Z","shell.execute_reply.started":"2024-01-18T15:07:36.912979Z","shell.execute_reply":"2024-01-18T15:07:36.923742Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in dataloader_val:\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:07:53.441738Z","iopub.execute_input":"2024-01-18T15:07:53.442778Z","iopub.status.idle":"2024-01-18T15:07:53.450594Z","shell.execute_reply.started":"2024-01-18T15:07:53.442735Z","shell.execute_reply":"2024-01-18T15:07:53.449713Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\n\n\nfor epoch in tqdm(range(1, epochs+1)):\n    \n    model.train()\n    \n    loss_train_total = 0\n\n    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n    for batch in progress_bar:\n\n        model.zero_grad()\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }       \n\n        outputs = model(**inputs)\n        \n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n        \n        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n         \n        \n    torch.save(model.state_dict(), f'/kaggle/working/finetuned_BERT_epoch_{epoch}.model')\n        \n    tqdm.write(f'\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total/len(dataloader_train)            \n    tqdm.write(f'Training loss: {loss_train_avg}')\n    \n    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n    val_f1 = f1_score_func(predictions, true_vals)\n    tqdm.write(f'Validation loss: {val_loss}')\n    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:09:50.972962Z","iopub.execute_input":"2024-01-18T15:09:50.973397Z","iopub.status.idle":"2024-01-18T15:12:11.324994Z","shell.execute_reply.started":"2024-01-18T15:09:50.973366Z","shell.execute_reply":"2024-01-18T15:12:11.323942Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f49d9e3a7e2842fe9c442d24f00520c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1\nTraining loss: 4.087772956848145\nValidation loss: 4.022597871043465\nF1 Score (Weighted): 0.08590222177178698\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 2\nTraining loss: 3.9101081638336184\nValidation loss: 3.9320993586020037\nF1 Score (Weighted): 0.11381773306906996\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 3\nTraining loss: 3.813375012397766\nValidation loss: 3.8801670507951216\nF1 Score (Weighted): 0.17916445153287258\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 4\nTraining loss: 3.7830126409530638\nValidation loss: 3.8801670507951216\nF1 Score (Weighted): 0.17916445153287258\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 5\nTraining loss: 3.7887882776260375\nValidation loss: 3.8801670507951216\nF1 Score (Weighted): 0.17916445153287258\n","output_type":"stream"}]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)\n\nmodel.to(device)\n\nmodel.load_state_dict(torch.load('/kaggle/working/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n\n_, predictions, true_vals = evaluate(dataloader_validation)\naccuracy_per_class(predictions, true_vals)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:13:52.475977Z","iopub.execute_input":"2024-01-18T15:13:52.476349Z","iopub.status.idle":"2024-01-18T15:13:54.463604Z","shell.execute_reply.started":"2024-01-18T15:13:52.476319Z","shell.execute_reply":"2024-01-18T15:13:54.462519Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Class: Bhuvan\nAccuracy: 0/1\n\nClass: Aadhaar\nAccuracy: 0/2\n\nClass: MGNREGA\nAccuracy: 0/2\n\nClass: NRSC\nAccuracy: 0/2\n\nClass: Bhuvan2D\nAccuracy: 0/1\n\nClass: Geospatial\nAccuracy: 0/1\n\nClass: Yuktdhara\nAccuracy: 0/2\n\nClass: Bhuvan3D\nAccuracy: 1/1\n\nClass: WBIS\nAccuracy: 1/2\n\nClass: RUSA\nAccuracy: 1/1\n\nClass: GI\nAccuracy: 0/1\n\nClass: Flycatch\nAccuracy: 1/1\n\nClass: NCERT\nAccuracy: 0/1\n\nClass: GIS\nAccuracy: 1/1\n\nClass: Tourism\nAccuracy: 1/2\n\nClass: Hpfor\nAccuracy: 0/2\n\nClass: TelFor\nAccuracy: 1/1\n\nClass: PunFor\nAccuracy: 0/2\n\nClass: UkFor\nAccuracy: 1/1\n\nClass: KarFor\nAccuracy: 1/1\n\nClass: NDEM\nAccuracy: 0/2\n\nClass: Thematic\nAccuracy: 0/2\n\nClass: Agro\nAccuracy: 0/1\n\nClass: PMKSY\nAccuracy: 0/2\n\nClass: Heatwave\nAccuracy: 0/1\n\nClass: Ganga\nAccuracy: 0/1\n\nClass: NARL\nAccuracy: 0/1\n\nClass: HarState\nAccuracy: 0/2\n\nClass: Saras\nAccuracy: 0/1\n\nClass: Satell\nAccuracy: 0/2\n\nClass: PMJVK\nAccuracy: 0/1\n\nClass: Anganwadi\nAccuracy: 0/1\n\nClass: Covid\nAccuracy: 2/2\n\nClass: Organiz\nAccuracy: 0/1\n\nClass: NOEDA\nAccuracy: 0/1\n\nClass: RBI\nAccuracy: 0/1\n\nClass: Geoportal\nAccuracy: 0/2\n\nClass: AmTourism\nAccuracy: 0/2\n\nClass: LudMun\nAccuracy: 1/2\n\nClass: Toll\nAccuracy: 0/1\n\nClass: KALAMTARI\nAccuracy: 0/1\n\nClass: Geomorph\nAccuracy: 0/2\n\nClass: AgroPortal\nAccuracy: 0/1\n\nClass: DeltaPortal\nAccuracy: 1/2\n\nClass: CDMAPortal\nAccuracy: 0/1\n\nClass: AndhraSat\nAccuracy: 0/1\n\nClass: Multilingual\nAccuracy: 0/2\n\nClass: GeoTaggingLight\nAccuracy: 0/1\n\nClass: GeoTaggingAgri\nAccuracy: 0/2\n\nClass: AIBP\nAccuracy: 0/1\n\nClass: MahaWater\nAccuracy: 0/2\n\nClass: PMGSY\nAccuracy: 0/2\n\nClass: Collab\nAccuracy: 0/2\n\nClass: PunHer\nAccuracy: 0/1\n\nClass: PunGIS\nAccuracy: 0/2\n\nClass: LudMunCollab\nAccuracy: 0/1\n\nClass: AIBPCollab\nAccuracy: 0/2\n\nClass: IMD\nAccuracy: 0/2\n\nClass: Register\nAccuracy: 0/2\n\nClass: 2DHelp\nAccuracy: 0/2\n\nClass: BhuvanFind\nAccuracy: 1/2\n\nClass: Admin\nAccuracy: 0/1\n\nClass: NavMap\nAccuracy: 1/2\n\nClass: Drawing\nAccuracy: 0/2\n\nClass: AddPoint\nAccuracy: 0/1\n\nClass: AddLine\nAccuracy: 0/1\n\nClass: AddPolygon\nAccuracy: 0/1\n\nClass: Area\nAccuracy: 0/1\n\nClass: Distance\nAccuracy: 0/1\n\nClass: Pan\nAccuracy: 0/2\n\nClass: Land\nAccuracy: 0/2\n\nClass: Weather2D\nAccuracy: 0/2\n\nClass: Ocean2D\nAccuracy: 1/1\n\nClass: Disaster2D\nAccuracy: 0/1\n\nClass: 3Don2D\nAccuracy: 0/2\n\nClass: Dissemination\nAccuracy: 0/2\n\nClass: Visualization\nAccuracy: 0/1\n\nClass: Statistics\nAccuracy: 0/2\n\nClass: Analysis\nAccuracy: 0/2\n\nClass: Metadata\nAccuracy: 0/1\n\nClass: WebService\nAccuracy: 1/1\n\nClass: Layers\nAccuracy: 0/2\n\nClass: Information\nAccuracy: 0/2\n\nClass: Tools\nAccuracy: 0/2\n\nClass: NOEDASatellite\nAccuracy: 0/1\n\nClass: NOEDACrop\nAccuracy: 0/1\n\nClass: NOEDAAWiFS\nAccuracy: 0/2\n\nClass: NOEDAWater\nAccuracy: 0/2\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:21:52.706165Z","iopub.execute_input":"2024-01-18T15:21:52.707320Z","iopub.status.idle":"2024-01-18T15:21:52.712253Z","shell.execute_reply.started":"2024-01-18T15:21:52.707271Z","shell.execute_reply":"2024-01-18T15:21:52.711170Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\n# Your input text\ninput_text = \"how to register at bhuvan\"\n\n# Tokenize and encode the input text\ninputs = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True)\ninput_ids = inputs['input_ids'].to(device)\nattention_mask = inputs['attention_mask'].to(device)\n\n# Make predictions\nwith torch.no_grad():\n    output = model(input_ids=input_ids, attention_mask=attention_mask)\n\n# Extract predicted probabilities or class labels\npredicted_probabilities = torch.softmax(output.logits, dim=1).cpu().numpy()\npredicted_class = np.argmax(predicted_probabilities, axis=-1)\n\n# Print the results\nprint(\"Predicted probabilities:\", predicted_probabilities)\nprint(\"Predicted class:\", predicted_class)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:23:14.921829Z","iopub.execute_input":"2024-01-18T15:23:14.922872Z","iopub.status.idle":"2024-01-18T15:23:14.950000Z","shell.execute_reply.started":"2024-01-18T15:23:14.922834Z","shell.execute_reply":"2024-01-18T15:23:14.948875Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Predicted probabilities: [[0.01205402 0.00678871 0.00580697 0.00866903 0.01225773 0.01121108\n  0.01235777 0.00606379 0.01430028 0.0147843  0.01166353 0.01222698\n  0.00690184 0.00899304 0.01864684 0.00728631 0.01337449 0.01198034\n  0.01024485 0.01356276 0.00950969 0.01273645 0.01280288 0.00961967\n  0.01187383 0.00675393 0.01757831 0.00904988 0.01593163 0.01607915\n  0.01182196 0.01401507 0.00540755 0.008975   0.01375524 0.00863925\n  0.00900889 0.00717433 0.00682692 0.01013758 0.00970669 0.01348936\n  0.0126135  0.01725973 0.01246408 0.00629694 0.01153642 0.00897702\n  0.00896007 0.00577681 0.00994997 0.00846006 0.00976122 0.01078334\n  0.0141584  0.01439384 0.0191335  0.01608367 0.01216887 0.00917387\n  0.0116261  0.01291068 0.0124333  0.00988087 0.01066578 0.00849536\n  0.01092464 0.00977497 0.01470074 0.00858203 0.01504172 0.00772466\n  0.00789098 0.009669   0.01038978 0.01101698 0.019224   0.01257592\n  0.01256517 0.01201769 0.02039632 0.01239308 0.01257324 0.00931434\n  0.01510507 0.01452705 0.01164214 0.00791916]]\nPredicted class: [80]\n","output_type":"stream"}]},{"cell_type":"code","source":"key_list = list(label_dict.keys())\nval_list = list(label_dict.values())\n \n# print key with val 100\nposition = val_list.index(predicted_class)\nprint(key_list[position])","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:25:19.753192Z","iopub.execute_input":"2024-01-18T15:25:19.754019Z","iopub.status.idle":"2024-01-18T15:25:19.759849Z","shell.execute_reply.started":"2024-01-18T15:25:19.753968Z","shell.execute_reply":"2024-01-18T15:25:19.758855Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"WebService\n","output_type":"stream"}]},{"cell_type":"code","source":"key_list","metadata":{"execution":{"iopub.status.busy":"2024-01-18T15:26:13.902976Z","iopub.execute_input":"2024-01-18T15:26:13.903369Z","iopub.status.idle":"2024-01-18T15:26:13.913119Z","shell.execute_reply.started":"2024-01-18T15:26:13.903339Z","shell.execute_reply":"2024-01-18T15:26:13.911873Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"['Bhuvan',\n 'Aadhaar',\n 'MGNREGA',\n 'NRSC',\n 'Bhuvan2D',\n 'Geospatial',\n 'Yuktdhara',\n 'Bhuvan3D',\n 'WBIS',\n 'RUSA',\n 'GI',\n 'Flycatch',\n 'NCERT',\n 'GIS',\n 'Tourism',\n 'Hpfor',\n 'TelFor',\n 'PunFor',\n 'UkFor',\n 'KarFor',\n 'NDEM',\n 'Thematic',\n 'Agro',\n 'PMKSY',\n 'Heatwave',\n 'Ganga',\n 'NARL',\n 'HarState',\n 'Saras',\n 'Satell',\n 'PMJVK',\n 'Anganwadi',\n 'Covid',\n 'Organiz',\n 'NOEDA',\n 'RBI',\n 'Geoportal',\n 'AmTourism',\n 'LudMun',\n 'Toll',\n 'KALAMTARI',\n 'Geomorph',\n 'AgroPortal',\n 'DeltaPortal',\n 'CDMAPortal',\n 'AndhraSat',\n 'Multilingual',\n 'GeoTaggingLight',\n 'GeoTaggingAgri',\n 'AIBP',\n 'MahaWater',\n 'PMGSY',\n 'Collab',\n 'PunHer',\n 'PunGIS',\n 'LudMunCollab',\n 'AIBPCollab',\n 'IMD',\n 'Register',\n '2DHelp',\n 'BhuvanFind',\n 'Admin',\n 'NavMap',\n 'Drawing',\n 'AddPoint',\n 'AddLine',\n 'AddPolygon',\n 'Area',\n 'Distance',\n 'Pan',\n 'Land',\n 'Weather2D',\n 'Ocean2D',\n 'Disaster2D',\n '3Don2D',\n 'Dissemination',\n 'Visualization',\n 'Statistics',\n 'Analysis',\n 'Metadata',\n 'WebService',\n 'Layers',\n 'Information',\n 'Tools',\n 'NOEDASatellite',\n 'NOEDACrop',\n 'NOEDAAWiFS',\n 'NOEDAWater']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}